{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xrzjgYR7lU3"
      },
      "source": [
        "# Praktikum 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TVOvDrtdWg6",
        "outputId": "23581560-d6b3-4df0-cce0-6914a41f92a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total data: (955320, 17)\n",
            "Subset data: (10000, 17)\n",
            "Subset data: (10000, 17)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sfati\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
            "[WinError 2] The system cannot find the file specified\n",
            "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
            "  warnings.warn(\n",
            "  File \"c:\\Users\\sfati\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
            "    cpu_info = subprocess.run(\n",
            "        \"wmic CPU Get NumberOfCores /Format:csv\".split(),\n",
            "        capture_output=True,\n",
            "        text=True,\n",
            "    )\n",
            "  File \"c:\\Users\\sfati\\anaconda3\\Lib\\subprocess.py\", line 554, in run\n",
            "    with Popen(*popenargs, **kwargs) as process:\n",
            "         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\sfati\\anaconda3\\Lib\\subprocess.py\", line 1039, in __init__\n",
            "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
            "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "                        pass_fds, cwd, env,\n",
            "                        ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "                        gid, gids, uid, umask,\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
            "                        start_new_session, process_group)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\sfati\\anaconda3\\Lib\\subprocess.py\", line 1554, in _execute_child\n",
            "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
            "                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
            "                             # no special security\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<4 lines>...\n",
            "                             cwd,\n",
            "                             ^^^^\n",
            "                             startupinfo)\n",
            "                             ^^^^^^^^^^^^\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exact NN done in 0.518 s\n",
            "Annoy done in 0.461 s\n",
            "HNSW done in 0.205 s\n",
            "Annoy done in 0.461 s\n",
            "HNSW done in 0.205 s\n",
            "FAISS IVF done in 0.057 s\n",
            "\n",
            "Top-5 neighbors for first song:\n",
            "Exact NN: [   0 6847 7747 5962 4665]\n",
            "Annoy:    [0, 6847, 7747, 5962, 4665]\n",
            "HNSW:     [   0 6847 7747 5962 4665]\n",
            "FAISS:    [   0 6847 7747 5962 4665]\n",
            "\n",
            "Summary runtime:\n",
            "Exact NN : 0.518 s\n",
            "Annoy    : 0.461 s\n",
            "HNSW     : 0.205 s\n",
            "FAISS    : 0.057 s\n",
            "FAISS IVF done in 0.057 s\n",
            "\n",
            "Top-5 neighbors for first song:\n",
            "Exact NN: [   0 6847 7747 5962 4665]\n",
            "Annoy:    [0, 6847, 7747, 5962, 4665]\n",
            "HNSW:     [   0 6847 7747 5962 4665]\n",
            "FAISS:    [   0 6847 7747 5962 4665]\n",
            "\n",
            "Summary runtime:\n",
            "Exact NN : 0.518 s\n",
            "Annoy    : 0.461 s\n",
            "HNSW     : 0.205 s\n",
            "FAISS    : 0.057 s\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from annoy import AnnoyIndex\n",
        "import hnswlib\n",
        "import faiss\n",
        "import time\n",
        "\n",
        "# ===============================\n",
        "#  Load dataset (lokal)\n",
        "# ===============================\n",
        "df = pd.read_csv(\"C:\\\\kuliah\\\\Machine Leaning\\\\2341720003_ML_2025\\\\data\\\\songs_with_attributes_and_lyrics.csv\")\n",
        "\n",
        "# Cek ukuran awal\n",
        "print(\"Total data:\", df.shape)\n",
        "\n",
        "df = df.sample(10000, random_state=42)\n",
        "print(\"Subset data:\", df.shape)\n",
        "\n",
        "# ===============================\n",
        "#  Siapkan fitur numerik\n",
        "# ===============================\n",
        "features = ['danceability', 'energy', 'loudness', 'speechiness',\n",
        "            'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
        "X = df[features].values\n",
        "\n",
        "# Standarisasi fitur\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "k = 10  # jumlah nearest neighbors\n",
        "\n",
        "# ===============================\n",
        "#  Exact Nearest Neighbor\n",
        "# ===============================\n",
        "start = time.time()\n",
        "nn = NearestNeighbors(n_neighbors=k, algorithm='brute', metric='euclidean')\n",
        "nn.fit(X_scaled)\n",
        "dist_exact, idx_exact = nn.kneighbors(X_scaled)\n",
        "time_exact = time.time() - start\n",
        "print(f\"Exact NN done in {time_exact:.3f} s\")\n",
        "\n",
        "# ===============================\n",
        "#  Annoy\n",
        "# ===============================\n",
        "start = time.time()\n",
        "f = X_scaled.shape[1]\n",
        "index_annoy = AnnoyIndex(f, 'euclidean')\n",
        "for i, v in enumerate(X_scaled):\n",
        "    index_annoy.add_item(i, v)\n",
        "index_annoy.build(10)\n",
        "idx_annoy = [index_annoy.get_nns_by_vector(v, k) for v in X_scaled]\n",
        "time_annoy = time.time() - start\n",
        "print(f\"Annoy done in {time_annoy:.3f} s\")\n",
        "\n",
        "# ===============================\n",
        "#  HNSW\n",
        "# ===============================\n",
        "start = time.time()\n",
        "p_hnsw = hnswlib.Index(space='l2', dim=X_scaled.shape[1])\n",
        "p_hnsw.init_index(max_elements=X_scaled.shape[0], ef_construction=100, M=8)\n",
        "p_hnsw.add_items(X_scaled)\n",
        "p_hnsw.set_ef(100)\n",
        "idx_hnsw, dist_hnsw = p_hnsw.knn_query(X_scaled, k=k)\n",
        "time_hnsw = time.time() - start\n",
        "print(f\"HNSW done in {time_hnsw:.3f} s\")\n",
        "\n",
        "# ===============================\n",
        "#  FAISS IVF\n",
        "# ===============================\n",
        "start = time.time()\n",
        "quantizer = faiss.IndexFlatL2(X_scaled.shape[1])\n",
        "index_faiss = faiss.IndexIVFFlat(quantizer, X_scaled.shape[1], 50, faiss.METRIC_L2)\n",
        "index_faiss.train(X_scaled)\n",
        "index_faiss.add(X_scaled)\n",
        "index_faiss.nprobe = 5\n",
        "dist_faiss, idx_faiss = index_faiss.search(X_scaled, k)\n",
        "time_faiss = time.time() - start\n",
        "print(f\"FAISS IVF done in {time_faiss:.3f} s\")\n",
        "\n",
        "# ===============================\n",
        "#  Contoh hasil\n",
        "# ===============================\n",
        "print(\"\\nTop-5 neighbors for first song:\")\n",
        "print(f\"Exact NN: {idx_exact[0][:5]}\")\n",
        "print(f\"Annoy:    {idx_annoy[0][:5]}\")\n",
        "print(f\"HNSW:     {idx_hnsw[0][:5]}\")\n",
        "print(f\"FAISS:    {idx_faiss[0][:5]}\")\n",
        "\n",
        "# ===============================\n",
        "#  Ringkasan waktu\n",
        "# ===============================\n",
        "print(\"\\nSummary runtime:\")\n",
        "print(f\"Exact NN : {time_exact:.3f} s\")\n",
        "print(f\"Annoy    : {time_annoy:.3f} s\")\n",
        "print(f\"HNSW     : {time_hnsw:.3f} s\")\n",
        "print(f\"FAISS    : {time_faiss:.3f} s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-2kcwmYs8E2"
      },
      "source": [
        "**Analisis**\n",
        "Semua metode approximate (Annoy, HNSW, FAISS) mampu meniru hasil brute-force dengan waktu jauh lebih cepat.\n",
        "FAISS adalah yang paling efisien secara waktu, sehingga paling direkomendasikan untuk dataset besar seperti jutaan lagu Spotify.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
